================================================================
IMPLEMENTATION PLAN — GraphQL CLI Tool (gqlt)
Language: Go
Goal: Minimal, composable command‑line client for running GraphQL ops

CURRENT APPROACH: Using native HTTP client instead of GraphQL libraries
- Full control over request/response handling
- Native operation name support
- Authentication via standard HTTP headers
- No external GraphQL library dependencies
- Minimal dependencies (just cobra and color)
================================================================

---------------------------------------------------------------
PHASE 1 | PROJECT INITIALIZATION
---------------------------------------------------------------

[x] 1. Initialize "gqlt"
    go mod init github.com/kluzzebass/gqlt

[x] 2. Add module dependencies
    go get github.com/spf13/cobra@latest
    go get github.com/fatih/color@latest (optional pretty output)
    Note: Using native HTTP client instead of GraphQL library for full control
    Note: Authentication handled via headers, no OAuth2 library needed

[x] 3. Base layout
    /cmd
      root.go
      run.go
      introspect.go
      describe.go
      test.go
      schema_diff.go
    /internal
      /config
      /io
      /output
    /main.go

[x] 4. main.go content:
    package main
    import "github.com/kluzzebass/gqlt/cmd"
    func main() { cmd.Execute() }

[x] 5. cmd/root.go
    Define the root Cobra command "gqlt"
    Version: 0.1.x
    PersistentFlags: (e.g. global --config)
    Example:
      var rootCmd = &cobra.Command{Use: "gqlt"}
      func Execute() { cobra.CheckErr(rootCmd.Execute()) }

---------------------------------------------------------------
PHASE 2 | RUN COMMAND (core)
---------------------------------------------------------------

Purpose: Execute GraphQL operation (query or mutation)

[x] 6. cmd/run.go
    Use: "run"
    Short: "Execute a GraphQL operation against an endpoint"

[x] 7. Define flags with short options:
    -u, --url string                 (GraphQL endpoint; required if not in config)
    -q, --query string               (inline GraphQL document)
    -Q, --query-file string          (path to .graphql file)
    -o, --operation string           (operationName)
    -v, --vars string                (JSON object)
    -V, --vars-file string           (path to JSON file)
    -H, --header key=value           (repeatable)
    -f, --file name=path             (file uploads; repeatable)
    -F, --files-list string          (file containing list of files to upload)
    -c, --config path                (optional; override default)
    -O, --out json|pretty|raw        (output mode: json=formatted, pretty=colored, raw=compact; default json)
    -U, --username string            (username for basic authentication)
    -p, --password string            (password for basic authentication)
    Note: Bearer tokens handled via -H "Authorization: Bearer <token>"

[x] 8. Input validation rules:
    - if both --query and --query-file => error
    - if neither => read full stdin as query
    - if both --vars and --vars-file => error
    - headers accumulate across occurrences
    - files accumulate across occurrences
    - if --config given, merge config values before network call

[x] 9. Implement helper resolution:

    // loadQuery: returns string
    if runFlags.query != "" return runFlags.query
    else if runFlags.queryFile != "" => read file
    else => read stdin until EOF

    // loadVars: returns map[string]interface{}
    if --vars => json.Unmarshal
    if --vars-file => read + Unmarshal
    else => empty map

    // parseHeaders: split by first '='
    result[k] = v for each --header occurrence

    // parseFiles: map[name] = path for each --file occurrence

[x] 10. Run GraphQL call using native HTTP client:
    - Build GraphQL payload with query, operationName, variables
    - Create HTTP POST request to GraphQL endpoint
    - Set Content-Type: application/json
    - Add custom headers
    - Execute request with authenticated HTTP client
    - Parse JSON response into map[string]interface{}

[x] 11. Error handling:
    if err != nil => print to stderr, exit 1
    if result["errors"] exists and non-empty => exit 2

[x] 12. Output handler:
    switch outMode:
      "json": formatted JSON with indentation (default)
      "pretty": colorized formatted JSON with syntax highlighting
      "raw": unformatted JSON (no indentation, compact)

Exit codes:
0  success, no errors
1  system/CLI/network error
2  GraphQL response contained "errors" or test/schema diff failures

---------------------------------------------------------------
PHASE 3 | CONFIG FILES ✅ COMPLETE
---------------------------------------------------------------

IMPLEMENTATION NOTES:
- Added AI-friendly _comment fields for self-documentation
- Implemented clone command instead of generic templates (more useful)
- Removed template system - clone existing configs is more practical
- All config commands working: show, list, set, use, create, delete, init, clone
- AI-friendly commands: describe, validate, examples
- Full integration with run command - CLI flags override config values

Config location search order:
1. --config flag (explicit override)
2. OS-specific default path:
   - Linux: ~/.config/gqlt/config.json
   - macOS: ~/Library/Application Support/gqlt/config.json  
   - Windows: %APPDATA%/gqlt/config.json
3. ./.gqlt/config.json (only when explicitly specified via --config)

[x] 13. internal/config/config.go:
    type Config struct {
        Current   string                    `json:"current"`   // active config name (defaults to "default")
        Configs   map[string]ConfigEntry    `json:"configs"`   // named configurations
    }
    
    type ConfigEntry struct {
        Endpoint string            `json:"endpoint"`
        Headers  map[string]string `json:"headers"`
        Defaults struct {
            Out string `json:"out"`
        } `json:"defaults"`
        Comment string `json:"_comment,omitempty"` // AI-friendly documentation
    }
    
    // Default configuration is always available and used when:
    // - No config file exists
    // - Current config doesn't exist
    // - No specific config is specified

[x] 14. Load(path):
    reads JSON, returns *Config
    if path empty => search in standard paths
    fallback = GetDefaultConfig() if not found

[x] 15. Merge(cli *Config, cfg *Config):
    - CLI values override config values
    - headers merge (CLI overwrites)
    - default Out fallback from cfg if not set
    return merged *Config

[x] 16. cmd/config.go (IMPLEMENTED)
    subcommands:
      gqlt config show [name]           (show current or named config)
      gqlt config list                  (list all configurations)
      gqlt config set <name> <key> <value>  (set value in named config)
      gqlt config use <name>           (switch to named config)
      gqlt config create <name>         (create new named config)
      gqlt config delete <name>         (delete named config)
      gqlt config init                  (create default config file)
      gqlt config clone <source> <target> (clone existing configuration)
      
      # AI-friendly commands
      gqlt config describe              (show schema and examples)
      gqlt config validate              (check config file syntax)
      gqlt config examples              (show usage examples)
      
    reads/updates JSON file on disk
    
    Note: "default" config is always available and used as fallback
    Note: Removed template system - clone is more useful

[x] 17. Example config file structure (AI-friendly):
    {
      "current": "production",
      "configs": {
        "default": {
          "endpoint": "https://api.example.com/graphql",
          "headers": {
            "Authorization": "Bearer your-token-here",
            "X-API-Key": "your-api-key-here"
          },
          "defaults": {
            "out": "pretty"
          },
          "_comment": "Default configuration - used when no specific config is active"
        },
        "production": {
          "endpoint": "https://api.company.com/graphql",
          "headers": {
            "Authorization": "Bearer prod-token-123"
          },
          "defaults": {
            "out": "json"
          }
        },
        "staging": {
          "endpoint": "https://staging-api.company.com/graphql", 
          "headers": {
            "Authorization": "Bearer staging-token-456"
          },
          "defaults": {
            "out": "pretty"
          }
        },
        "local": {
          "endpoint": "http://localhost:4000/graphql",
          "headers": {},
          "defaults": {
            "out": "pretty"
          }
        }
      },
      "_schema": {
        "endpoint": "GraphQL endpoint URL (required)",
        "headers": "HTTP headers to include with requests",
        "defaults.out": "Default output mode: json|pretty|raw"
      }
    }

[x] 18. Example usage:
    # Initialize config file (creates default config)
    gqlt config init
    
    # AI-friendly setup
    gqlt config describe              # Show schema and examples
    gqlt config validate              # Check config validity
    gqlt config examples              # Show usage examples
    
    # Create additional configurations
    gqlt config create production
    gqlt config set production endpoint https://api.company.com/graphql
    gqlt config set production headers.Authorization "Bearer token123"
    
    # Clone existing configurations
    gqlt config clone production staging  
    gqlt config set staging endpoint https://staging-api.company.com/graphql
    
    # Switch between configs
    gqlt config use production
    gqlt run -q '{ me { name } }'  # uses production config
    
    gqlt config use staging
    gqlt run -q '{ me { name } }'  # uses staging config
    
    gqlt config use default
    gqlt run -q '{ me { name } }'  # uses default config
    
    # Override specific values
    gqlt run -q '{ me { name } }' -u https://override.com/graphql
    
    # AI-friendly debugging
    gqlt config show --format=json    # Structured output for AI parsing
    gqlt config list --format=table  # Tabular data for easy parsing
    gqlt config docs                  # Generate documentation

[x] 19. AI-friendly features:
    - Self-documenting config structure with _comment fields ✅
    - Rich help system with examples and suggestions ✅
    - Validation with actionable error messages ✅
    - Clone system for common use cases ✅ (replaces templates)
    - Structured output formats (json, table) for AI parsing ✅
    - Context-aware error messages with solutions ✅
    - Documentation generation for AI understanding ✅
    
    IMPLEMENTED FEATURES:
    - gqlt config describe (schema and examples)
    - gqlt config validate (with error messages)
    - gqlt config examples (usage patterns)
    - gqlt config clone (replaces template system)
    - JSON/table output formats
    - _comment fields for self-documentation

[x] 20. Template examples: (REMOVED - replaced with clone system)
    # OLD: Generic templates (removed as not useful)
    # NEW: Clone existing configurations (more practical)
    gqlt config clone production staging    # Clone production to staging
    gqlt config clone default local         # Clone default to local
    gqlt config clone countries production  # Clone countries to production

---------------------------------------------------------------
PHASE 4 | REFACTOR TO LAYERED ARCHITECTURE
---------------------------------------------------------------

PURPOSE: Separate command parsing from business logic for better testability

[x] 21. Create internal/graphql package:
    - Move GraphQL execution logic from cmd/run.go
    - Client struct with methods for different operations
    - Separate concerns: HTTP client, request building, response parsing
    - Make it testable without Cobra dependencies
    
    type Client struct {
        endpoint string
        headers  map[string]string
        httpClient *http.Client
    }
    
    func (c *Client) Execute(query string, variables map[string]interface{}, operationName string) (*Response, error)
    func (c *Client) SetHeaders(headers map[string]string)
    func (c *Client) SetAuth(username, password string)

[x] 22. Create internal/input package:
    - Move file loading logic from cmd/run.go
    - Pure functions for file operations
    - No Cobra dependencies
    
    func LoadQuery(query, queryFile string) (string, error)
    func LoadVariables(vars, varsFile string) (map[string]interface{}, error)
    func LoadHeaders(headers []string) (map[string]string, error)
    func ParseFiles(files []string) (map[string]string, error)

[x] 23. Create internal/output package:
    - Move output formatting logic from cmd/run.go
    - Pure functions for different output modes
    - No Cobra dependencies
    
    func FormatJSON(data interface{}) error
    func FormatPretty(data interface{}) error  
    func FormatRaw(data interface{}) error

[x] 24. Refactor cmd/run.go:
    - Only Cobra command parsing and flag gathering
    - Delegate all business logic to internal packages
    - Much simpler and focused on CLI concerns
    
    func runGraphQL(cmd *cobra.Command, args []string) error {
        // 1. Parse flags
        // 2. Load config
        // 3. Create internal/graphql.Client
        // 4. Execute operation
        // 5. Format output
    }

[x] 25. Refactor cmd/config.go:
    - Move config business logic to internal/config
    - cmd/config.go only handles CLI parsing
    - internal/config handles all config operations
    
    type Manager struct {
        path string
    }
    
    func (m *Manager) Load() (*Config, error)
    func (m *Manager) Save(config *Config) error
    func (m *Manager) Create(name string) error
    func (m *Manager) Delete(name string) error
    // etc.

[x] 26. Add comprehensive tests:
    - Unit tests for each internal package
    - Integration tests for cmd packages
    - Mock HTTP clients for testing
    - Test all error conditions
    - Test all output formats

BENEFITS:
- Testable: Each layer can be tested independently
- Maintainable: Clear separation of concerns
- Reusable: Internal packages can be used by other tools
- Extensible: Easy to add new commands or features

---------------------------------------------------------------
PHASE 5 | INTROSPECTION AND DESCRIBE
---------------------------------------------------------------

[x] 27. cmd/introspect.go
    - endpoint via flag/config
    - issue introspection query:
      query IntrospectionQuery { __schema { types { name kind fields { name type { name kind } } } } }
    - save to per-configuration schema cache (dual format: JSON + GraphQL SDL)
    - flags:
       --refresh (ignore cache)
       --out path
       --summary (stdout short)
    - per-configuration caching: each config has its own schema files
    - config directory support: --config-dir points to directory containing config.json and schemas/
    - dual format storage: <config>.json (machine-readable) + <config>.graphqls (human-readable)

[x] 28. cmd/describe.go
    - read schema JSON file
    - build index:
        map[TypeName]TypeMetadata
        map[Query|Mutation|Subscription]FieldSummary
    - arguments:
        gqlt describe Query
        gqlt describe Query.product
        gqlt describe Type.Product
    - options:
        --json  (exact node JSON)
        --summary (plain text)
    - typical output:
        TYPE Query
        ├── product(id: ID!): Product
        └── search(q: String!): [Product]

---------------------------------------------------------------
PHASE 6 | TEST AND SCHEMA DIFF
---------------------------------------------------------------

[ ] 29. cmd/test.go
    Purpose: load YAML/JSON suite of operations + expected matches
    TestSpec structure:
        - name string
        - query string or file
        - vars  map[string]interface{}
        - expect map[string]interface{}
    Execution:
        for each test:
            runGraphQL()
            validate: each expect key -> check via JSONPath or simple dotted traversal
            count passes/fails
    Exit codes: 0 all pass, 2 failures.

[ ] 30. cmd/schema_diff.go
    Inputs: two file paths
    Compare type/field maps.
    Diff struct:
       AddedTypes, RemovedTypes
       AddedFields, RemovedFields
    Output options: default text table, or --json
    Typical:
       TYPE+ Order
       FIELD- Product.oldField

---------------------------------------------------------------
PHASE 7 | AUTHENTICATION SUPPORT
---------------------------------------------------------------

[x] 31. Add simple authentication support to run command:
    -U, --username string              (basic auth username)
    -p, --password string          (basic auth password)
    -t, --token string            (bearer token for authentication)
    -k, --api-key string         (API key for authentication)
    Note: Bearer tokens can also be handled via -H "Authorization: Bearer <token>"

[x] 32. Implement simple authentication:
    - Bearer: Use -t/--token flag or -H "Authorization: Bearer <token>" header
    - Basic: Use -U/--username and -p/--password flags
    - API Key: Use -k/--api-key flag (sets X-API-Key header)
    - None: No authentication (default)

[~] 33. Update config structure for simple auth:
    Note: CANCELLED - Current approach using headers field is more flexible and secure
    Current config already supports auth via headers:
    {
        "headers": {
            "Authorization": "Bearer token123"
        }
    }
    This is better than separate auth fields because:
    - More flexible (supports any auth method)
    - More secure (no plaintext passwords)
    - Standard HTTP approach

---------------------------------------------------------------
PHASE 8 | ~~INTERNAL UTILITIES~~ (SKIPPED - REDUNDANT)
---------------------------------------------------------------

~~[ ] 34. internal/io/io.go~~ (REDUNDANT - already implemented in internal/input)
~~[ ] 35. internal/output/output.go~~ (REDUNDANT - already have internal/output with Formatter)
~~[ ] 36. internal/errors~~ (REDUNDANT - already have consistent error handling)

REASON: Phase 7 is no longer relevant because we've already implemented better,
more comprehensive solutions in our layered architecture. The proposed utilities
would actually be a step backward from what we have.

---------------------------------------------------------------
PHASE 9 | HANDLING FILE UPLOADS
---------------------------------------------------------------

[x] 37. Support file uploads:
    -f, --file flags parsed as "name=path" (repeatable)
    -F, --files-list string (file containing list of files to upload)
    - Parse file flags into map[name]path
    - Validate file existence before attach
    - Implemented multipart/form-data for file uploads
    - Added ExecuteWithFiles method to GraphQL client
    - Added ParseFilesFromList function for batch file uploads

[x] 38. Example use in shell:
    # Simple query (formatted JSON)
    gqlt run -u https://api.example.com/graphql -q '{ __typename }'
    
    # Query with variables (colored output)
    gqlt run -u https://api.example.com/graphql -Q query.graphql -v '{"id": "123"}' -O pretty
    
    # Compact output for scripting
    gqlt run -u https://api.example.com/graphql -q '{ me { name } }' -O raw | jq '.data.me.name'
    
    # With authentication
    gqlt run -u https://api.example.com/graphql -q '{ me { name } }' -H "Authorization: Bearer <token>"
    
    # File upload (when implemented)
    gqlt run -u https://api.example.com/graphql -Q upload.graphql -f file=./photo.jpg

    Output modes:
    - json: formatted JSON with indentation (default)
    - pretty: colorized formatted JSON for development
    - raw: compact unformatted JSON for scripting

---------------------------------------------------------------
PHASE 10 | BUILD / VALIDATION
---------------------------------------------------------------

[x] 39. Build command:
    go build -o bin/gqlt .
    verify binary size < 15MB static (9.2MB - PASS)
    test: ./bin/gqlt --help

[x] 40. Manual tests:
    ./gqlt run --url <endpoint> --query '{__typename}'
    ./gqlt run --query-file q.graphql --vars '{"id":"1"}'
    ./gqlt introspect
    ./gqlt describe Query

[x] 41. CI / Testing:
    Write unit tests for config merge, IO helpers
    run: go test ./... (all packages passing)

[ ] 42. Release binaries and build automation:
    - Create justfile with recipes for common development tasks
    - Add VERSION file for semantic versioning management
    - Implement automated version bumping (patch/minor/major)
      * Commands: just bump-patch, just bump-minor, just bump-major
      * Reads current version from VERSION file, increments appropriate component
      * Writes new version back to VERSION file, optionally creates git commit/tag
      * VERSION file gets embedded in binary at build time via go:embed
    - Add cross-platform build recipes (linux, darwin, windows)
    - Create distribution packaging with checksums
    - Add release workflow with git tagging
    - Include development setup and testing recipes
    - Add dependency management and code quality recipes

---------------------------------------------------------------
PHASE 11 | DOCUMENTATION GENERATION
---------------------------------------------------------------

[ ] 43. internal/docs/generator.go
    - go generate directive: //go:generate go run internal/docs/generator.go
    - single Cobra command structure parser
    - extract help text, descriptions, flags, and examples
    - generate both README.md and gqlt.1 from same source
    - support multiple output formats (markdown, manpage)
    - include usage examples and configuration guides

[ ] 44. Documentation workflow
    - go generate ./... (runs all //go:generate directives)
    - single parser generates both README.md and gqlt.1
    - automated documentation updates in CI/CD
    - no duplication - one source of truth for documentation
    - uses standard Go tooling

---------------------------------------------------------------
PHASE 12 | LIBRARY AND AI AGENT OPTIMIZATION
---------------------------------------------------------------

[x] 45. Create public API package
    - Move internal packages to root-level public API (not pkg/)
    - Create root-level files: client.go, types.go, config.go, schema.go, introspect.go
    - Refactor top-level functions as methods on appropriate types
    - Core Client methods: Execute, ExecuteWithFiles, SetAuth, SetHeaders, Introspect
    - Config methods: Load, Save, GetCurrent, SetCurrent, Create, Delete, SetValue, Validate
    - Schema Analyzer methods: GetSummary, FindType, FindField, GetTypeDescription, GetFieldDescription
    - Introspect methods: IntrospectSchema, SaveSchema, SaveSchemaDual
    - Input utilities as methods: LoadQuery, LoadVariables, ParseFiles (on Client or separate Input type)
    - Output utilities as methods: FormatJSON, FormatPretty, FormatRaw (on Response or separate Formatter type)
    - Enable single import: import "github.com/kluzzebass/gqlt"
    - Add proper GoDoc comments to all public APIs
    - Document public APIs with examples

[x] 46. AI agent optimization
    - Add structured output modes (--format json) for all commands
    - Implement machine-readable error messages with error codes
    - Add --quiet mode for automation scenarios
    - Create AI-friendly help text with examples and common patterns
    - Add validation commands that return structured results

[x] 47. Test library integration
    - Create example test files showing library usage
    - Add test utilities for common GraphQL testing patterns
    - Document how to use gqlt as a library in Go tests
    - Add mock server utilities for testing
    - Create integration test examples

[x] 48. Library documentation and examples
    - Add GoDoc comments to all public APIs
    - Update README.md with library usage examples
    - Add example programs in examples/ directory
    - Document common patterns for both CLI and library usage
    - Add migration guide from other GraphQL libraries

---------------------------------------------------------------
PHASE 13 | MCP SERVER INTEGRATION
---------------------------------------------------------------

[ ] 49. MCP server foundation
    - Add MCP server wrapper around existing gqlt functionality
    - Implement JSON-RPC 2.0 server for AI agent communication
    - Create MCPServer struct with embedded Client, Config, and Analyzer
    - Add session management for concurrent AI agent requests
    - Enable both CLI and MCP server modes in single binary

[ ] 50. MCP tools implementation
    - execute_query: Run GraphQL queries with variables and operation names
    - introspect_schema: Get complete GraphQL schema information
    - describe_type: Analyze specific GraphQL types and fields
    - validate_query: Check GraphQL query validity against schema
    - upload_files: Handle file uploads in GraphQL mutations
    - get_config: Retrieve and manage GraphQL endpoint configurations
    - set_auth: Configure authentication (Bearer, Basic, API Key)

[ ] 51. MCP resources and prompts
    - Expose GraphQL schemas as MCP resources for AI exploration
    - Provide schema summaries and type information as resources
    - Create prompts for common GraphQL operations and patterns
    - Add resource discovery for available GraphQL endpoints
    - Implement schema caching and resource management

[ ] 52. MCP server testing and documentation
    - Add comprehensive tests for MCP server functionality
    - Create example MCP client integrations
    - Document MCP server usage for AI agent developers
    - Add configuration examples for different AI platforms
    - Create migration guide from other GraphQL MCP servers

---------------------------------------------------------------
COMPLETE WHEN:
---------------------------------------------------------------
[ ] gqlt buildable single binary (Linux, macOS, Windows)
[ ] run, introspect, describe functional
[ ] supports headers, bearer tokens, file uploads
[ ] outputs consistent JSON or colorized pretty form
[ ] uses exit codes appropriately
[ ] minimal third‑party dependencies
[ ] comprehensive README.md generated from help system
[ ] man page generation working